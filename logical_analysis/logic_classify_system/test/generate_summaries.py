"""
í…ŒìŠ¤íŠ¸ ê²°ê³¼ Summary ë¬¸ì„œ ìƒì„±

ë‘ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ê°ê° summary ë¬¸ì„œë¡œ ìƒì„±
"""

import sys
from pathlib import Path
from datetime import datetime
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from logical_analysis.logic_classify_system.config.labels import NORMAL_LABELS, SPECIAL_LABELS


def generate_normal_label_summary(stats: dict, total_files: int, output_path: Path) -> None:
    """Normal Label ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ Summary ë¬¸ì„œ ìƒì„±"""
    total_turns = stats['total_turns']
    normal_ratio = (stats['normal_count'] / total_turns * 100) if total_turns > 0 else 0
    special_ratio = (stats['special_count'] / total_turns * 100) if total_turns > 0 else 0
    
    summary_lines = [
        "# ì •ìƒ ë°œí™” ë°ì´í„°ì…‹ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ë¶„ì„ ë³´ê³ ì„œ (v2)",
        "",
        f"**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**ë°ì´í„°ì…‹**: temp_extract_stt (ì •ìƒ ë°œí™” ë°ì´í„°ì…‹)",
        f"**ë²„ì „**: v2 (Special Label ìš”ì¸ í•©ì‚° ë°©ì‹ ì ìš©)",
        "",
        "**ì£¼ìš” ë³€ê²½ì‚¬í•­**:",
        "- Special Label ì‹ ë¢°ë„: korcen + baseline ê·œì¹™ ìš”ì¸ë“¤ì„ í•©ì‚°í•˜ì—¬ ê³„ì‚°",
        "- Normal Label ì‹ ë¢°ë„ ì œê±°: ì •ìƒ ë°œí™”ë¡œ íŒë‹¨í•˜ê²Œ ëœ ê·¼ê±°ë¥¼ ì •ëŸ‰í™”í•˜ê¸° ì–´ë ¤ì›Œ ì œê±°",
        "- Special Label ìš”ì¸ë³„ ì ìˆ˜: ê° ìš”ì¸(`*_factor_score`)ì˜ ê¸°ì—¬ë„ ì œê³µ",
        "",
        "---",
        "",
        "## ğŸ“Š ìš”ì•½ í†µê³„",
        "",
        f"- **ì´ ì²˜ë¦¬ íŒŒì¼ ìˆ˜**: {total_files:,}ê°œ",
        f"- **ì´ ì„¸ì…˜ ìˆ˜**: {stats.get('total_sessions', 0):,}ê°œ",
        f"- **ì´ Turn ìˆ˜**: {total_turns:,}ê°œ",
        f"- **Normal Label ë¶„ë¥˜**: {stats['normal_count']:,}ê°œ ({normal_ratio:.2f}%)",
        f"- **Special Label ë¶„ë¥˜**: {stats['special_count']:,}ê°œ ({special_ratio:.2f}%)",
        "",
        "---",
        "",
        "## ğŸ“‹ Normal Label ë¶„í¬",
        "",
    ]
    
    # Normal Label ë¶„í¬
    for label, count in stats['normal_labels'].most_common():
        ratio = (count / stats['normal_count'] * 100) if stats['normal_count'] > 0 else 0
        avg_confidence = (
            stats['label_details'][label]['confidence_sum'] / count
            if count > 0 else 0
        )
        summary_lines.extend([
            f"### {label}",
            "",
            f"- **ê°œìˆ˜**: {count:,}ê°œ ({ratio:.2f}%)",
            f"- **í‰ê·  ì‹ ë¢°ë„**: {avg_confidence:.3f}",
            ""
        ])
        
        # ì˜ˆì‹œ ì¶”ê°€
        examples = stats.get('normal_label_examples', {}).get(label, [])
        if examples:
            summary_lines.append("**ë¶„ë¥˜ ì˜ˆì‹œ**:")
            summary_lines.append("")
            for i, ex in enumerate(examples, 1):
                summary_lines.extend([
                    f"{i}. **ë°œí™”**: {ex['text']}",
                    f"   - **ì‹ ë¢°ë„**: {ex['confidence']:.3f}",
                ])
                if ex.get('probabilities'):
                    summary_lines.append(f"   - **í™•ë¥  ë¶„í¬**: {ex['probabilities']}")
                if ex.get('feature_scores'):
                    # Special Label ì‹ ë¢°ë„ (ìš”ì¸ë“¤ í•©ì‚°)
                    special_conf = ex['feature_scores'].get('special_label_confidence', 0.0)
                    if special_conf > 0:
                        summary_lines.append(f"   - **Special Label ì‹ ë¢°ë„**: {special_conf:.3f}")
                        
                        # Special Label ìš”ì¸ë³„ ì ìˆ˜
                        factor_scores = []
                        for factor_name in ['profanity_factor_score', 'threat_factor_score', 
                                          'sexual_harassment_factor_score', 'hate_speech_factor_score',
                                          'unreasonable_demand_factor_score', 'repetition_factor_score']:
                            factor_score = ex['feature_scores'].get(factor_name, 0.0)
                            if factor_score > 0:
                                factor_label = factor_name.replace('_factor_score', '').upper()
                                factor_scores.append(f"{factor_label}: {factor_score:.3f}")
                        
                        if factor_scores:
                            summary_lines.append(f"   - **Special Label ìš”ì¸ ì ìˆ˜**: {', '.join(factor_scores)}")
                summary_lines.append("")
            summary_lines.append("")
    
    # Special Labelë¡œ ë¶„ë¥˜ëœ ì¼€ì´ìŠ¤
    special_examples = stats.get('special_label_examples', [])
    if special_examples:
        summary_lines.extend([
            "---",
            "",
            "## âš ï¸ Normal Labelë¡œ ë¶„ë¥˜ë˜ì§€ ì•Šì€ ì¼€ì´ìŠ¤",
            "",
            f"ì´ **{len(special_examples)}ê°œ**ì˜ ì¼€ì´ìŠ¤ê°€ Special Labelë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "",
        ])
        
        for i, ex in enumerate(special_examples, 1):
            summary_lines.extend([
                f"### ì¼€ì´ìŠ¤ {i}",
                "",
                f"- **ì„¸ì…˜ ID**: {ex['session_id']}",
                f"- **ë°œí™”**: {ex['text']}",
                f"- **ë¶„ë¥˜ëœ Label**: {ex['label']} ({ex.get('label_type', 'SPECIAL')})",
                f"- **ì‹ ë¢°ë„**: {ex['confidence']:.3f}",
                ""
            ])
            
            # íŠ¹ì§•ì  ì ìˆ˜
            if ex.get('feature_scores'):
                summary_lines.append("**íŠ¹ì§•ì  ì ìˆ˜**:")
                feature_scores = ex['feature_scores']
                
                # Special Label ì‹ ë¢°ë„ (ìš”ì¸ë“¤ í•©ì‚°)
                special_conf = feature_scores.get('special_label_confidence', 0.0)
                if special_conf > 0:
                    summary_lines.append(f"- Special Label ì‹ ë¢°ë„ (ìš”ì¸ í•©ì‚°): {special_conf:.3f}")
                
                # Special Label ìš”ì¸ë³„ ì ìˆ˜
                factor_scores = {}
                for factor_name in ['profanity_factor_score', 'threat_factor_score', 
                                  'sexual_harassment_factor_score', 'hate_speech_factor_score',
                                  'unreasonable_demand_factor_score', 'repetition_factor_score']:
                    factor_score = feature_scores.get(factor_name, 0.0)
                    if factor_score > 0:
                        factor_label = factor_name.replace('_factor_score', '').replace('_', ' ').title()
                        factor_scores[factor_label] = factor_score
                
                if factor_scores:
                    summary_lines.append("  **Special Label ìš”ì¸ë³„ ê¸°ì—¬ë„**:")
                    for factor_label, factor_score in sorted(factor_scores.items(), key=lambda x: x[1], reverse=True):
                        summary_lines.append(f"  - {factor_label}: {factor_score:.3f}")
                
                # ê¸°íƒ€ íŠ¹ì§•ì  ì ìˆ˜
                other_scores = {}
                for key, value in feature_scores.items():
                    if value > 0 and key not in ['special_label_confidence'] and not key.endswith('_factor_score'):
                        other_scores[key] = value
                
                if other_scores:
                    summary_lines.append("  **ê¸°íƒ€ íŠ¹ì§•ì  ì ìˆ˜**:")
                    for key, value in sorted(other_scores.items(), key=lambda x: x[1], reverse=True):
                        summary_lines.append(f"  - {key}: {value:.3f}")
                
                summary_lines.append("")
            
            # ì¶”ì¶œëœ íŠ¹ì§•ì 
            if ex.get('extracted_features'):
                summary_lines.append("**ì¶”ì¶œëœ íŠ¹ì§•ì **:")
                for key, value in ex['extracted_features'].items():
                    if value:
                        if isinstance(value, list):
                            summary_lines.append(f"- {key}: {value[:3]}")
                        else:
                            summary_lines.append(f"- {key}: {value}")
                summary_lines.append("")
            
            if ex.get('probabilities'):
                summary_lines.append(f"**í™•ë¥  ë¶„í¬**: {ex['probabilities']}")
                summary_lines.append("")
            
            summary_lines.append("")
    
    # ì‹ ë¢°ë„ í†µê³„
    summary_lines.extend([
        "---",
        "",
        "## ğŸ“ˆ ì‹ ë¢°ë„ í†µê³„",
        "",
    ])
    
    if stats['confidence_stats']['normal']:
        normal_confidences = stats['confidence_stats']['normal']
        summary_lines.extend([
            "### Normal Label",
            "",
            f"- **í‰ê·  ì‹ ë¢°ë„**: {sum(normal_confidences) / len(normal_confidences):.3f}",
            f"- **ìµœì†Œ ì‹ ë¢°ë„**: {min(normal_confidences):.3f}",
            f"- **ìµœëŒ€ ì‹ ë¢°ë„**: {max(normal_confidences):.3f}",
            "",
        ])
    
    if stats['confidence_stats']['special']:
        special_confidences = stats['confidence_stats']['special']
        summary_lines.extend([
            "### Special Label",
            "",
            f"- **í‰ê·  ì‹ ë¢°ë„**: {sum(special_confidences) / len(special_confidences):.3f}",
            f"- **ìµœì†Œ ì‹ ë¢°ë„**: {min(special_confidences):.3f}",
            f"- **ìµœëŒ€ ì‹ ë¢°ë„**: {max(special_confidences):.3f}",
            "",
        ])
    
    # ìµœì¢… í‰ê°€
    summary_lines.extend([
        "---",
        "",
        "## âœ… ìµœì¢… í‰ê°€",
        "",
        f"**Normal Label ë¶„ë¥˜ ë¹„ìœ¨**: {normal_ratio:.2f}%",
        "",
    ])
    
    if normal_ratio >= 80:
        summary_lines.append("âœ… ì •ìƒ ë°œí™” ë°ì´í„°ì…‹ì´ Normal Labelë¡œ ì˜ ë¶„ë¥˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
    elif normal_ratio >= 60:
        summary_lines.append("âš ï¸ Normal Label ë¶„ë¥˜ ë¹„ìœ¨ì´ ë‹¤ì†Œ ë‚®ìŠµë‹ˆë‹¤. ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        summary_lines.append("âŒ Normal Label ë¶„ë¥˜ ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ë¶„ë¥˜ ë¡œì§ì„ ì¬ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.")
    
    summary_lines.append("")
    
    # íŒŒì¼ ì €ì¥
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(summary_lines))
    
    print(f"[ì™„ë£Œ] Summary ë¬¸ì„œ ì €ì¥: {output_path}")


def generate_special_label_summary(stats: dict, total_files: int, output_path: Path) -> None:
    """Special Label ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ Summary ë¬¸ì„œ ìƒì„±"""
    total_turns = stats['total_turns']
    normal_ratio = (stats['normal_count'] / total_turns * 100) if total_turns > 0 else 0
    special_ratio = (stats['special_count'] / total_turns * 100) if total_turns > 0 else 0
    
    summary_lines = [
        "# ë¬¸ì œ ë°œí™” ë°ì´í„°ì…‹ Special Label ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ë¶„ì„ ë³´ê³ ì„œ (v2)",
        "",
        f"**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**ë°ì´í„°ì…‹**: talksets_stt (ìœ¤ë¦¬ ê²€ì¦ ë°ì´í„°ì…‹ - ë¬¸ì œ ë°œí™” ë¹„ìœ¨ ë†’ìŒ)",
        f"**ë²„ì „**: v2 (Special Label ìš”ì¸ í•©ì‚° ë°©ì‹ ì ìš©)",
        "",
        "**ì£¼ìš” ë³€ê²½ì‚¬í•­**:",
        "- Special Label ì‹ ë¢°ë„: korcen + baseline ê·œì¹™ ìš”ì¸ë“¤ì„ í•©ì‚°í•˜ì—¬ ê³„ì‚°",
        "- ìš”ì¸ ê°œìˆ˜ ê°€ì¤‘ì¹˜: Special Label ìš”ì¸ì´ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ìƒìŠ¹",
        "- Special Label ìš”ì¸ë³„ ì ìˆ˜: ê° ìš”ì¸(`*_factor_score`)ì˜ ê¸°ì—¬ë„ ì œê³µ",
        "",
        "---",
        "",
        "## ğŸ“Š ìš”ì•½ í†µê³„",
        "",
        f"- **ì´ ì²˜ë¦¬ íŒŒì¼ ìˆ˜**: {total_files:,}ê°œ",
        f"- **ì´ Turn ìˆ˜**: {total_turns:,}ê°œ",
        f"- **Normal Label ë¶„ë¥˜**: {stats['normal_count']:,}ê°œ ({normal_ratio:.2f}%)",
        f"- **Special Label ë¶„ë¥˜**: {stats['special_count']:,}ê°œ ({special_ratio:.2f}%)",
        "",
        "---",
        "",
        "## ğŸš¨ Special Label ìƒì„¸ ë¶„í¬",
        "",
    ]
    
    # Special Label ìƒì„¸ ë¶„í¬
    for label, count in stats['special_labels'].most_common():
        ratio = (count / stats['special_count'] * 100) if stats['special_count'] > 0 else 0
        avg_confidence = (
            stats['label_details'][label]['confidence_sum'] / count
            if count > 0 else 0
        )
        
        summary_lines.extend([
            f"### {label}",
            "",
            f"- **ê°œìˆ˜**: {count:,}ê°œ ({ratio:.2f}%)",
            f"- **í‰ê·  ì‹ ë¢°ë„**: {avg_confidence:.3f}",
            ""
        ])
        
        # íŠ¹ì§•ì  ì ìˆ˜ í†µê³„
        special_stats = stats.get('special_label_breakdown', {}).get(label, {})
        if special_stats and special_stats.get('count', 0) > 0:
            count_for_stats = special_stats['count']
            avg_profanity = special_stats['profanity_score_sum'] / count_for_stats if count_for_stats > 0 else 0
            avg_threat = special_stats['threat_score_sum'] / count_for_stats if count_for_stats > 0 else 0
            
            summary_lines.append("**í‰ê·  íŠ¹ì§•ì  ì ìˆ˜**:")
            summary_lines.append(f"- ìš•ì„¤ ì ìˆ˜: {avg_profanity:.3f}")
            summary_lines.append(f"- ìœ„í˜‘ ì ìˆ˜: {avg_threat:.3f}")
            
            # ê° íŠ¹ì§•ì ë³„ í‰ê· 
            for feature_name, feature_values in special_stats.get('feature_stats', {}).items():
                if feature_values:
                    avg_value = sum(feature_values) / len(feature_values)
                    summary_lines.append(f"- {feature_name}: {avg_value:.3f}")
            summary_lines.append("")
            
            # ì˜ˆì‹œ
            examples = special_stats.get('examples', [])
            if examples:
                summary_lines.append("**ë¶„ë¥˜ ì˜ˆì‹œ**:")
                summary_lines.append("")
                for i, ex in enumerate(examples[:3], 1):  # ìµœëŒ€ 3ê°œ
                    summary_lines.extend([
                        f"{i}. **ë°œí™”**: {ex['text']}",
                        f"   - **ì‹ ë¢°ë„**: {ex['confidence']:.3f}",
                    ])
                    
                    # íŠ¹ì§•ì  ì ìˆ˜
                    if ex.get('feature_scores'):
                        feature_scores = ex['feature_scores']
                        
                        # Special Label ì‹ ë¢°ë„ (ìš”ì¸ë“¤ í•©ì‚°)
                        special_conf = feature_scores.get('special_label_confidence', 0.0)
                        if special_conf > 0:
                            summary_lines.append(f"   - **Special Label ì‹ ë¢°ë„ (ìš”ì¸ í•©ì‚°)**: {special_conf:.3f}")
                        
                        # Special Label ìš”ì¸ë³„ ì ìˆ˜
                        factor_scores = {}
                        for factor_name in ['profanity_factor_score', 'threat_factor_score', 
                                          'sexual_harassment_factor_score', 'hate_speech_factor_score',
                                          'unreasonable_demand_factor_score', 'repetition_factor_score']:
                            factor_score = feature_scores.get(factor_name, 0.0)
                            if factor_score > 0:
                                factor_label = factor_name.replace('_factor_score', '').replace('_', ' ').title()
                                factor_scores[factor_label] = factor_score
                        
                        if factor_scores:
                            summary_lines.append("   - **Special Label ìš”ì¸ë³„ ê¸°ì—¬ë„**:")
                            for factor_label, factor_score in sorted(factor_scores.items(), key=lambda x: x[1], reverse=True):
                                summary_lines.append(f"     - {factor_label}: {factor_score:.3f}")
                        
                        # ê¸°íƒ€ íŠ¹ì§•ì  ì ìˆ˜
                        other_scores = {}
                        for key in ['profanity_score', 'threat_score', 'sexual_harassment_score', 
                                   'hate_speech_score', 'unreasonable_demand_score', 'repetition_keyword_score']:
                            if key in feature_scores and feature_scores[key] > 0:
                                other_scores[key] = feature_scores[key]
                        
                        if other_scores:
                            summary_lines.append("   - **ê¸°íƒ€ íŠ¹ì§•ì  ì ìˆ˜**:")
                            for key, value in sorted(other_scores.items(), key=lambda x: x[1], reverse=True):
                                summary_lines.append(f"     - {key}: {value:.3f}")
                    
                    # ì¶”ì¶œëœ íŠ¹ì§•ì 
                    if ex.get('extracted_features'):
                        summary_lines.append("   - **ì¶”ì¶œëœ íŠ¹ì§•ì **:")
                        for key, value in ex['extracted_features'].items():
                            if value:
                                if isinstance(value, list):
                                    summary_lines.append(f"     - {key}: {value[:2]}")
                                else:
                                    summary_lines.append(f"     - {key}: {value}")
                    
                    summary_lines.append("")
            summary_lines.append("")
    
    # Normal Label ë¶„í¬ (ê°„ë‹¨íˆ)
    if stats['normal_labels']:
        summary_lines.extend([
            "---",
            "",
            "## ğŸ“‹ Normal Label ë¶„í¬ (ì˜¤ë¶„ë¥˜ ì¼€ì´ìŠ¤)",
            "",
        ])
        for label, count in stats['normal_labels'].most_common():
            ratio = (count / stats['normal_count'] * 100) if stats['normal_count'] > 0 else 0
            summary_lines.append(f"- **{label}**: {count:,}ê°œ ({ratio:.2f}%)")
        summary_lines.append("")
    
    # ì‹ ë¢°ë„ í†µê³„
    summary_lines.extend([
        "---",
        "",
        "## ğŸ“ˆ ì‹ ë¢°ë„ í†µê³„",
        "",
    ])
    
    if stats['confidence_stats']['special']:
        special_confidences = stats['confidence_stats']['special']
        summary_lines.extend([
            "### Special Label",
            "",
            f"- **í‰ê·  ì‹ ë¢°ë„**: {sum(special_confidences) / len(special_confidences):.3f}",
            f"- **ìµœì†Œ ì‹ ë¢°ë„**: {min(special_confidences):.3f}",
            f"- **ìµœëŒ€ ì‹ ë¢°ë„**: {max(special_confidences):.3f}",
            "",
        ])
    
    if stats['confidence_stats']['normal']:
        normal_confidences = stats['confidence_stats']['normal']
        summary_lines.extend([
            "### Normal Label (ì˜¤ë¶„ë¥˜)",
            "",
            f"- **í‰ê·  ì‹ ë¢°ë„**: {sum(normal_confidences) / len(normal_confidences):.3f}",
            f"- **ìµœì†Œ ì‹ ë¢°ë„**: {min(normal_confidences):.3f}",
            f"- **ìµœëŒ€ ì‹ ë¢°ë„**: {max(normal_confidences):.3f}",
            "",
        ])
    
    # ìµœì¢… í‰ê°€
    summary_lines.extend([
        "---",
        "",
        "## âœ… ìµœì¢… í‰ê°€",
        "",
        f"**Special Label ë¶„ë¥˜ ë¹„ìœ¨**: {special_ratio:.2f}%",
        f"**Normal Label ë¶„ë¥˜ ë¹„ìœ¨**: {normal_ratio:.2f}%",
        "",
    ])
    
    if special_ratio >= 30:
        summary_lines.append("âœ… ë¬¸ì œ ë°œí™” ë°ì´í„°ì…‹ì´ Special Labelë¡œ ì˜ ë¶„ë¥˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
    elif special_ratio >= 15:
        summary_lines.append("âš ï¸ Special Label ë¶„ë¥˜ ë¹„ìœ¨ì´ ë‹¤ì†Œ ë‚®ìŠµë‹ˆë‹¤. ì¼ë¶€ ë¬¸ì œ ë°œí™”ê°€ Normalë¡œ ë¶„ë¥˜ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        summary_lines.append("âŒ Special Label ë¶„ë¥˜ ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ë¶„ë¥˜ ë¡œì§ì„ ì¬ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.")
    
    summary_lines.append("")
    
    # íŒŒì¼ ì €ì¥
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(summary_lines))
    
    print(f"[ì™„ë£Œ] Summary ë¬¸ì„œ ì €ì¥: {output_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    script_dir = Path(__file__).parent
    output_dir = script_dir / 'test_results'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("Summary ë¬¸ì„œ ìƒì„± ë„êµ¬")
    print("í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•œ í›„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()

