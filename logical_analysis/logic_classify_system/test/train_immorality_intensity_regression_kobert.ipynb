{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Talkset ë¹„ìœ¤ë¦¬ ê°•ë„ Regression ëª¨ë¸ í•™ìŠµ (KoBERT ê¸°ë°˜)\n",
        "\n",
        "Talkset ë°ì´í„°ì…‹ì˜ `intensity` (ë¹„ìœ¤ë¦¬ ê°•ë„) ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” KoBERT ê¸°ë°˜ Regression ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "## Talkset ë°ì´í„° êµ¬ì¡°\n",
        "\n",
        "Talkset ë°ì´í„°ì…‹ì—ëŠ” ë‹¤ìŒ í•„ë“œê°€ ìˆìŠµë‹ˆë‹¤:\n",
        "- `is_immoral`: boolean (ìœ¤ë¦¬ì  ë¬¸ì œ ì—¬ë¶€)\n",
        "- `intensity`: float (ë¹„ìœ¤ë¦¬ ê°•ë„ ì ìˆ˜, 0.0 ~ ì•½ 2.0)\n",
        "- `intensity_sum`: int (ê°•ë„ í•©ê³„)\n",
        "- `types`: list (ë¹„ìœ¤ë¦¬ ìœ í˜•, ì˜ˆ: \"HATE\", \"CENSURE\" ë“±)\n",
        "- `text`: str (ë°œí™” í…ìŠ¤íŠ¸)\n",
        "\n",
        "**í•™ìŠµ ëª©í‘œ**: ë°œí™” í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ë¹„ìœ¤ë¦¬ ê°•ë„(intensity)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” Regression ëª¨ë¸ í•™ìŠµ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "\n",
        "Colabì—ì„œ ì‹¤í–‰ ì‹œ ì²« ë²ˆì§¸ ì…€ì—ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install transformers torch numpy pandas scikit-learn tqdm\n",
        "\n",
        "# GPU í™•ì¸\n",
        "import torch\n",
        "print(f'CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ë° ì„¤ì •\n",
        "\n",
        "Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ importí•˜ê³  ê¸°ë³¸ ì„¤ì •ì„ í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'ì‚¬ìš© ì¥ì¹˜: {device}')\n",
        "print('ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Talkset ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
        "\n",
        "Talkset ë°ì´í„°ì…‹ì—ëŠ” ë‹¤ìŒ í•„ë“œê°€ ìˆìŠµë‹ˆë‹¤:\n",
        "- `is_immoral`: boolean (ìœ¤ë¦¬ì  ë¬¸ì œ ì—¬ë¶€)\n",
        "- `intensity`: float (ë¹„ìœ¤ë¦¬ ê°•ë„ ì ìˆ˜, 0.0 ~ ì•½ 2.0) - **ì´ê²ƒì´ ì˜ˆì¸¡ ëŒ€ìƒ**\n",
        "- `intensity_sum`: int (ê°•ë„ í•©ê³„)\n",
        "- `types`: list (ë¹„ìœ¤ë¦¬ ìœ í˜•, ì˜ˆ: \"HATE\", \"CENSURE\" ë“±)\n",
        "- `text`: str (ë°œí™” í…ìŠ¤íŠ¸) - **ì´ê²ƒì´ ì…ë ¥**\n",
        "\n",
        "**ë¹„ìœ¤ë¦¬ ê°•ë„ í•™ìŠµ ì²´ê³„:**\n",
        "- Talkset ë°ì´í„°ì…‹ì— `intensity` í•„ë“œê°€ ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŒ\n",
        "- ë‹¤ìˆ˜ì˜ í‰ê°€ì(voter)ê°€ ê° ë¬¸ì¥ì˜ ë¹„ìœ¤ë¦¬ ê°•ë„ë¥¼ í‰ê°€\n",
        "- `intensity`ëŠ” í‰ê·  ê°•ë„ ê°’ (0.0 ~ ì•½ 2.0)\n",
        "- `intensity_sum`ì€ ëª¨ë“  í‰ê°€ìì˜ ê°•ë„ í•©ê³„\n",
        "- `is_immoral=True`ì¸ ë¬¸ì¥ì€ `intensity > 0`ì„ ê°€ì§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° íŒŒì¼ í™•ì¸ (Colabì—ì„œëŠ” íŒŒì¼ ì—…ë¡œë“œ í•„ìš”)\n",
        "# !wget https://example.com/talksets-train-6.json  # ë˜ëŠ” íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
        "data_file = 'talksets-train-6.json'  # ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •\n",
        "\n",
        "try:\n",
        "    with open(data_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    print(f'ì´ ëŒ€í™” ìˆ˜: {len(data)}')\n",
        "    \n",
        "    # ì²« ë²ˆì§¸ ë¹„ìœ¤ë¦¬ ë¬¸ì¥ ì°¾ê¸°\n",
        "    for talk in data[:10]:\n",
        "        for sentence in talk.get('sentences', []):\n",
        "            if sentence.get('is_immoral', False):\n",
        "                print(f'\\nìƒ˜í”Œ ë¹„ìœ¤ë¦¬ ë¬¸ì¥:')\n",
        "                print(f'  í…ìŠ¤íŠ¸: {sentence.get(\"text\", \"\")}')\n",
        "                print(f'  is_immoral: {sentence.get(\"is_immoral\")}')\n",
        "                print(f'  intensity: {sentence.get(\"intensity\")}')\n",
        "                print(f'  intensity_sum: {sentence.get(\"intensity_sum\")}')\n",
        "                print(f'  types: {sentence.get(\"types\", [])}')\n",
        "                break\n",
        "        else:\n",
        "            continue\n",
        "        break\n",
        "    \n",
        "    # í†µê³„ ê³„ì‚°\n",
        "    all_sentences = [s for talk in data for s in talk.get('sentences', [])]\n",
        "    immoral_sentences = [s for s in all_sentences if s.get('is_immoral', False)]\n",
        "    \n",
        "    print(f'\\nì „ì²´ ë¬¸ì¥ ìˆ˜: {len(all_sentences):,}')\n",
        "    print(f'ë¹„ìœ¤ë¦¬ ë¬¸ì¥ ìˆ˜: {len(immoral_sentences):,}')\n",
        "    \n",
        "    if immoral_sentences:\n",
        "        intensities = [s.get('intensity', 0.0) for s in immoral_sentences]\n",
        "        print(f'ë¹„ìœ¤ë¦¬ ë¬¸ì¥ Intensity í†µê³„:')\n",
        "        print(f'  í‰ê· : {np.mean(intensities):.3f}')\n",
        "        print(f'  ìµœì†Œ: {np.min(intensities):.3f}')\n",
        "        print(f'  ìµœëŒ€: {np.max(intensities):.3f}')\n",
        "        print(f'  í‘œì¤€í¸ì°¨: {np.std(intensities):.3f}')\n",
        "        \n",
        "except FileNotFoundError:\n",
        "    print(f'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_file}')\n",
        "    print('Colabì—ì„œëŠ” íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "\n",
        "Talkset JSON íŒŒì¼ì„ ë¡œë“œí•˜ê³ , í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_talkset_data(file_path: str, filter_immoral_only: bool = False) -> Tuple[List[str], List[float]]:\n",
        "    \"\"\"\n",
        "    Talkset ë°ì´í„° ë¡œë“œ\n",
        "    \n",
        "    Args:\n",
        "        file_path: talkset JSON íŒŒì¼ ê²½ë¡œ\n",
        "        filter_immoral_only: Trueì´ë©´ is_immoral=Trueì¸ ë¬¸ì¥ë§Œ ë¡œë“œ\n",
        "    \n",
        "    Returns:\n",
        "        (texts, intensities) íŠœí”Œ\n",
        "    \"\"\"\n",
        "    print(f'ë°ì´í„° ë¡œë“œ ì¤‘: {file_path}')\n",
        "    \n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    texts = []\n",
        "    intensities = []\n",
        "    \n",
        "    for talk in tqdm(data, desc='ëŒ€í™” ì²˜ë¦¬ ì¤‘'):\n",
        "        for sentence in talk.get('sentences', []):\n",
        "            text = sentence.get('text', '').strip()\n",
        "            is_immoral = sentence.get('is_immoral', False)\n",
        "            intensity = sentence.get('intensity', 0.0)\n",
        "            \n",
        "            # ë¹ˆ í…ìŠ¤íŠ¸ ì œì™¸\n",
        "            if not text:\n",
        "                continue\n",
        "            \n",
        "            # í•„í„°ë§ ì¡°ê±´\n",
        "            if filter_immoral_only and not is_immoral:\n",
        "                continue\n",
        "            \n",
        "            texts.append(text)\n",
        "            intensities.append(intensity)\n",
        "    \n",
        "    return texts, intensities\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ\n",
        "all_texts, all_intensities = load_talkset_data(\n",
        "    'talksets-train-6.json',\n",
        "    filter_immoral_only=False  # ëª¨ë“  ë¬¸ì¥ ì‚¬ìš© (ì •ìƒ ë°œí™”ëŠ” intensity=0)\n",
        ")\n",
        "\n",
        "print(f'\\nì´ ë¬¸ì¥ ìˆ˜: {len(all_texts):,}')\n",
        "print(f'  - intensity > 0: {sum(1 for i in all_intensities if i > 0):,}ê°œ')\n",
        "print(f'  - intensity = 0: {sum(1 for i in all_intensities if i == 0):,}ê°œ')\n",
        "print(f'\\nIntensity í†µê³„:')\n",
        "print(f'  í‰ê· : {np.mean(all_intensities):.3f}')\n",
        "print(f'  ìµœì†Œ: {np.min(all_intensities):.3f}')\n",
        "print(f'  ìµœëŒ€: {np.max(all_intensities):.3f}')\n",
        "print(f'  í‘œì¤€í¸ì°¨: {np.std(all_intensities):.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¶„í•  (í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸)\n",
        "# 1ì°¨ ë¶„í• : í•™ìŠµ+ê²€ì¦ / í…ŒìŠ¤íŠ¸\n",
        "train_val_texts, test_texts, train_val_intensities, test_intensities = train_test_split(\n",
        "    all_texts,\n",
        "    all_intensities,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 2ì°¨ ë¶„í• : í•™ìŠµ / ê²€ì¦\n",
        "train_texts, val_texts, train_intensities, val_intensities = train_test_split(\n",
        "    train_val_texts,\n",
        "    train_val_intensities,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(f'í•™ìŠµ ë°ì´í„°: {len(train_texts):,}ê°œ')\n",
        "print(f'ê²€ì¦ ë°ì´í„°: {len(val_texts):,}ê°œ')\n",
        "print(f'í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_texts):,}ê°œ')\n",
        "print(f'\\ní•™ìŠµ ë°ì´í„° Intensity í†µê³„:')\n",
        "print(f'  í‰ê· : {np.mean(train_intensities):.3f}')\n",
        "print(f'  ìµœì†Œ: {np.min(train_intensities):.3f}')\n",
        "print(f'  ìµœëŒ€: {np.max(train_intensities):.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Dataset í´ë˜ìŠ¤ ì •ì˜\n",
        "\n",
        "PyTorch Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ì—¬ talkset ë°ì´í„°ë¥¼ ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImmoralityIntensityDataset(Dataset):\n",
        "    \"\"\"ë¹„ìœ¤ë¦¬ ê°•ë„ Regressionì„ ìœ„í•œ Dataset\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        texts: List[str],\n",
        "        intensities: List[float],\n",
        "        tokenizer,\n",
        "        max_length: int = 128\n",
        "    ):\n",
        "        self.texts = texts\n",
        "        self.intensities = intensities\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx: int) -> Dict:\n",
        "        text = str(self.texts[idx])\n",
        "        intensity = float(self.intensities[idx])\n",
        "        \n",
        "        # í† í¬ë‚˜ì´ì§•\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(intensity, dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "print('Dataset í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. KoBERT ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "\n",
        "KoBERT ëª¨ë¸ì„ ë¡œë“œí•˜ê³  Regression íƒœìŠ¤í¬ì— ë§ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "**KoBERT Regression ëª¨ë¸ êµ¬ì¡°:**\n",
        "1. KoBERT Encoder: ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
        "2. Regression Head: ì¶œë ¥ ë ˆì´ì–´ì—ì„œ `num_labels=1`ë¡œ ì„¤ì •í•˜ì—¬ í•˜ë‚˜ì˜ ì‹¤ìˆ˜ ê°’(intensity) ì˜ˆì¸¡\n",
        "3. Loss Function: MSE (Mean Squared Error) ì‚¬ìš©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KoBERT ëª¨ë¸ëª…\n",
        "MODEL_NAME = 'monologg/kobert'  # ë˜ëŠ” 'skt/kobert-base-v1'\n",
        "\n",
        "print(f'KoBERT ëª¨ë¸ ë¡œë“œ ì¤‘: {MODEL_NAME}')\n",
        "\n",
        "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print('í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ')\n",
        "\n",
        "# Regression ëª¨ë¸ ë¡œë“œ (num_labels=1: í•˜ë‚˜ì˜ ì‹¤ìˆ˜ ê°’ ì˜ˆì¸¡)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=1,  # Regression: í•˜ë‚˜ì˜ ì‹¤ìˆ˜ ê°’ ì¶œë ¥\n",
        "    problem_type=\"regression\"  # Regression íƒœìŠ¤í¬ ëª…ì‹œ\n",
        ")\n",
        "\n",
        "# GPUë¡œ ì´ë™\n",
        "model = model.to(device)\n",
        "print(f'ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì¥ì¹˜: {device})')\n",
        "\n",
        "# ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}')\n",
        "print(f'í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {trainable_params:,}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Dataset ê°ì²´ ìƒì„±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset ê°ì²´ ìƒì„±\n",
        "MAX_LENGTH = 128  # ìµœëŒ€ í† í° ê¸¸ì´\n",
        "\n",
        "train_dataset = ImmoralityIntensityDataset(\n",
        "    train_texts,\n",
        "    train_intensities,\n",
        "    tokenizer,\n",
        "    max_length=MAX_LENGTH\n",
        ")\n",
        "\n",
        "val_dataset = ImmoralityIntensityDataset(\n",
        "    val_texts,\n",
        "    val_intensities,\n",
        "    tokenizer,\n",
        "    max_length=MAX_LENGTH\n",
        ")\n",
        "\n",
        "test_dataset = ImmoralityIntensityDataset(\n",
        "    test_texts,\n",
        "    test_intensities,\n",
        "    tokenizer,\n",
        "    max_length=MAX_LENGTH\n",
        ")\n",
        "\n",
        "print(f'í•™ìŠµ Dataset í¬ê¸°: {len(train_dataset)}')\n",
        "print(f'ê²€ì¦ Dataset í¬ê¸°: {len(val_dataset)}')\n",
        "print(f'í…ŒìŠ¤íŠ¸ Dataset í¬ê¸°: {len(test_dataset)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. í‰ê°€ ì§€í‘œ í•¨ìˆ˜ ì •ì˜\n",
        "\n",
        "Regression ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•œ ì§€í‘œ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤:\n",
        "- MSE (Mean Squared Error)\n",
        "- MAE (Mean Absolute Error)\n",
        "- RÂ² Score\n",
        "- RMSE (Root Mean Squared Error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    \n",
        "    # predictionsëŠ” (batch_size, 1) í˜•íƒœì˜ ë°°ì—´\n",
        "    # labelsëŠ” (batch_size,) í˜•íƒœì˜ ë°°ì—´\n",
        "    predictions = predictions.flatten()\n",
        "    labels = labels.flatten()\n",
        "    \n",
        "    mse = mean_squared_error(labels, predictions)\n",
        "    mae = mean_absolute_error(labels, predictions)\n",
        "    r2 = r2_score(labels, predictions)\n",
        "    \n",
        "    # RMSE ê³„ì‚°\n",
        "    rmse = np.sqrt(mse)\n",
        "    \n",
        "    return {\n",
        "        'mse': mse,\n",
        "        'rmse': rmse,\n",
        "        'mae': mae,\n",
        "        'r2': r2\n",
        "    }\n",
        "\n",
        "print('í‰ê°€ ì§€í‘œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. í•™ìŠµ ì„¤ì • (TrainingArguments)\n",
        "\n",
        "**KoBERT í•™ìŠµ ë¡œì§ ì„¤ëª…:**\n",
        "1. **ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©**: `monologg/kobert`ëŠ” í•œêµ­ì–´ ì½”í¼ìŠ¤ë¡œ ì‚¬ì „ í•™ìŠµëœ BERT ëª¨ë¸\n",
        "2. **Fine-tuning**: Regression íƒœìŠ¤í¬ì— ë§ê²Œ ì¶œë ¥ ë ˆì´ì–´ë¥¼ ìˆ˜ì •í•˜ê³  ì „ì²´ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •\n",
        "3. **Learning Rate**: 2e-5 (BERT ëª¨ë¸ì˜ ì¼ë°˜ì ì¸ í•™ìŠµë¥ , ì‘ê²Œ ì„¤ì •í•˜ì—¬ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ê³¼ë„í•˜ê²Œ ë³€ê²½í•˜ì§€ ì•ŠìŒ)\n",
        "4. **Batch Size**: GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì • (16 ë˜ëŠ” 32)\n",
        "5. **Loss Function**: MSE Loss (Regression íƒœìŠ¤í¬ì˜ í‘œì¤€ ì†ì‹¤ í•¨ìˆ˜)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•™ìŠµ ì„¤ì •\n",
        "OUTPUT_DIR = './kobert_immorality_intensity_regression'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=5,  # í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
        "    per_device_train_batch_size=16,  # í•™ìŠµ ë°°ì¹˜ í¬ê¸°\n",
        "    per_device_eval_batch_size=32,   # í‰ê°€ ë°°ì¹˜ í¬ê¸°\n",
        "    learning_rate=2e-5,  # í•™ìŠµë¥  (BERT ëª¨ë¸ì˜ ì¼ë°˜ì ì¸ í•™ìŠµë¥ )\n",
        "    weight_decay=0.01,   # L2 ì •ê·œí™”\n",
        "    warmup_steps=500,    # Warmup ìŠ¤í… ìˆ˜\n",
        "    \n",
        "    # í‰ê°€ ë° ì €ì¥ ì„¤ì •\n",
        "    evaluation_strategy='epoch',  # ê° ì—í¬í¬ë§ˆë‹¤ í‰ê°€\n",
        "    save_strategy='epoch',       # ê° ì—í¬í¬ë§ˆë‹¤ ì €ì¥\n",
        "    save_total_limit=3,          # ìµœëŒ€ ëª¨ë¸ íŒŒì¼ ìˆ˜ (ì´ì „ ëª¨ë¸ ìë™ ì‚­ì œ)\n",
        "    load_best_model_at_end=True, # í•™ìŠµ ì¢…ë£Œ ì‹œ ìµœì  ëª¨ë¸ ë¡œë“œ\n",
        "    metric_for_best_model='mse', # ìµœì  ëª¨ë¸ ì„ íƒ ê¸°ì¤€ (MSE ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
        "    greater_is_better=False,     # MSEëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ False\n",
        "    \n",
        "    # ë¡œê¹… ì„¤ì •\n",
        "    logging_dir=f'{OUTPUT_DIR}/logs',\n",
        "    logging_steps=100,  # 100 ìŠ¤í…ë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
        "    \n",
        "    # ê¸°íƒ€ ì„¤ì •\n",
        "    seed=42,\n",
        "    fp16=True,  # Mixed precision training (GPU ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì†ë„ í–¥ìƒ)\n",
        "    dataloader_num_workers=2,  # ë°ì´í„° ë¡œë”© ë³‘ë ¬ ì²˜ë¦¬\n",
        "    report_to='none'  # TensorBoard ë“± ì™¸ë¶€ ë¡œê¹… ë¹„í™œì„±í™” (í•„ìš”ì‹œ ë³€ê²½)\n",
        ")\n",
        "\n",
        "print('í•™ìŠµ ì„¤ì • ì™„ë£Œ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Trainer ê°ì²´ ìƒì„± ë° í•™ìŠµ\n",
        "\n",
        "**í•™ìŠµ ê³¼ì • ì„¤ëª…:**\n",
        "1. **Forward Pass**: ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ KoBERTë¡œ ì¸ì½”ë”©í•˜ì—¬ ë²¡í„° í‘œí˜„ ì¶”ì¶œ\n",
        "2. **Regression Head**: ë§ˆì§€ë§‰ ë ˆì´ì–´ì—ì„œ í•˜ë‚˜ì˜ ì‹¤ìˆ˜ ê°’(intensity) ì˜ˆì¸¡\n",
        "3. **Loss Calculation**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ intensity ê°’ì˜ MSE ê³„ì‚°\n",
        "4. **Backward Pass**: ì—­ì „íŒŒë¥¼ í†µí•´ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
        "5. **Evaluation**: ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (MSE, MAE, RÂ²)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainer ê°ì²´ ìƒì„±\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # ì¡°ê¸° ì¢…ë£Œ\n",
        ")\n",
        "\n",
        "print('Trainer ê°ì²´ ìƒì„± ì™„ë£Œ')\n",
        "print('í•™ìŠµ ì‹œì‘...')\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ\n",
        "train_history = trainer.train()\n",
        "\n",
        "print('\\ní•™ìŠµ ì™„ë£Œ!')\n",
        "print(f'í•™ìŠµ ì‹œê°„: {train_history.metrics[\"train_runtime\"]:.2f}ì´ˆ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ (ìµœì¢… í‰ê°€)\n",
        "\n",
        "ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… í‰ê°€\n",
        "print('=== í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ (ìµœì¢… í‰ê°€) ===\\n')\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "print('ğŸ“Š [ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼]')\n",
        "print(f'  MSE: {test_results[\"eval_mse\"]:.4f}')\n",
        "print(f'  RMSE: {test_results[\"eval_rmse\"]:.4f}')\n",
        "print(f'  MAE: {test_results[\"eval_mae\"]:.4f}')\n",
        "print(f'  RÂ² Score: {test_results[\"eval_r2\"]:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì¢… í‰ê°€\n",
        "print('í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ ì¤‘...')\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "print('\\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===')\n",
        "print(f'MSE: {test_results[\"eval_mse\"]:.4f}')\n",
        "print(f'RMSE: {test_results[\"eval_rmse\"]:.4f}')\n",
        "print(f'MAE: {test_results[\"eval_mae\"]:.4f}')\n",
        "print(f'RÂ² Score: {test_results[\"eval_r2\"]:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. ì˜ˆì¸¡ ì˜ˆì‹œ\n",
        "\n",
        "í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ì˜ ë¹„ìœ¤ë¦¬ ê°•ë„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
        "def predict_intensity(model, tokenizer, text: str, device) -> float:\n",
        "    \"\"\"ë‹¨ì¼ í…ìŠ¤íŠ¸ì˜ ë¹„ìœ¤ë¦¬ ê°•ë„ ì˜ˆì¸¡\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # í† í¬ë‚˜ì´ì§•\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    \n",
        "    # GPUë¡œ ì´ë™\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    \n",
        "    # ì˜ˆì¸¡\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predicted_intensity = outputs.logits.item()\n",
        "    \n",
        "    return max(0.0, predicted_intensity)  # ìŒìˆ˜ ë°©ì§€\n",
        "\n",
        "# ì˜ˆì¸¡ ì˜ˆì‹œ\n",
        "sample_texts = [\n",
        "    \"ì•ˆë…•í•˜ì„¸ìš”, ë¬¸ì˜ë“œë¦¬ê³  ì‹¶ì€ ê²ƒì´ ìˆìŠµë‹ˆë‹¤.\",\n",
        "    \"ì§€ê¸ˆ ë‹¹ì¥ í•´ê²°í•´ë‹¬ë¼ë‹ˆê¹!\",\n",
        "    \"ì›ë˜ í‹€ë”±ë“¤ì€ ëˆˆì¹˜ê°€ ì—†ì–´ì„œ ã…‹ã…‹ã…‹\",\n",
        "    \"í•´ê²° ëª»í•˜ë©´ ê³ ì†Œí•˜ê² ìŠµë‹ˆë‹¤.\"\n",
        "]\n",
        "\n",
        "print('=== ì˜ˆì¸¡ ì˜ˆì‹œ ===')\n",
        "for text in sample_texts:\n",
        "    predicted = predict_intensity(model, tokenizer, text, device)\n",
        "    print(f'\\në°œí™”: {text}')\n",
        "    print(f'ì˜ˆì¸¡ëœ ë¹„ìœ¤ë¦¬ ê°•ë„: {predicted:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. ëª¨ë¸ ì €ì¥\n",
        "\n",
        "í•™ìŠµëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìµœì¢… ëª¨ë¸ ì €ì¥\n",
        "final_model_path = f'{OUTPUT_DIR}/final_model'\n",
        "model.save_pretrained(final_model_path)\n",
        "tokenizer.save_pretrained(final_model_path)\n",
        "\n",
        "print(f'âœ“ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {final_model_path}')\n",
        "\n",
        "# í‰ê°€ ê²°ê³¼ ì €ì¥\n",
        "results_summary = {\n",
        "    'validation': {\n",
        "        'mse': float(val_results['eval_mse']),\n",
        "        'rmse': float(val_results['eval_rmse']),\n",
        "        'mae': float(val_results['eval_mae']),\n",
        "        'r2': float(val_results['eval_r2'])\n",
        "    },\n",
        "    'test': {\n",
        "        'mse': float(test_results['eval_mse']),\n",
        "        'rmse': float(test_results['eval_rmse']),\n",
        "        'mae': float(test_results['eval_mae']),\n",
        "        'r2': float(test_results['eval_r2'])\n",
        "    },\n",
        "    'training_info': {\n",
        "        'train_samples': len(train_texts),\n",
        "        'val_samples': len(val_texts),\n",
        "        'test_samples': len(test_texts),\n",
        "        'model_name': MODEL_NAME,\n",
        "        'max_length': MAX_LENGTH,\n",
        "        'train_files': TRAIN_DATA_FILES,\n",
        "        'val_file': VAL_DATA_FILE\n",
        "    }\n",
        "}\n",
        "\n",
        "# ê²°ê³¼ ìš”ì•½ ì €ì¥\n",
        "results_file = f'{OUTPUT_DIR}/evaluation_results.json'\n",
        "with open(results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f'âœ“ í‰ê°€ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {results_file}')\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('ğŸ“¦ ì €ì¥ëœ íŒŒì¼ ëª©ë¡:')\n",
        "print(f'  1. ëª¨ë¸ íŒŒì¼: {final_model_path}/')\n",
        "print(f'     - pytorch_model.bin')\n",
        "print(f'     - config.json')\n",
        "print(f'     - tokenizer ê´€ë ¨ íŒŒì¼ë“¤')\n",
        "print(f'  2. í‰ê°€ ê²°ê³¼: {results_file}')\n",
        "print('='*60)\n",
        "print('\\nğŸ“– ëª¨ë¸ ì ìš© ë°©ë²•:')\n",
        "print('   í”„ë¡œì íŠ¸ì˜ MODEL_APPLICATION_GUIDE.md íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.')\n",
        "print('   ë˜ëŠ” Colabì—ì„œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ:')\n",
        "print('   from google.colab import files')\n",
        "print('   !zip -r model.zip kobert_immorality_intensity_regression/final_model')\n",
        "print('   files.download(\"model.zip\")')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (Colab)\n",
        "\n",
        "Colabì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì„ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ì˜**: Colab ì„¸ì…˜ì´ ì¢…ë£Œë˜ë©´ íŒŒì¼ì´ ì‚­ì œë˜ë¯€ë¡œ, ë°˜ë“œì‹œ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ Google Driveì— ì €ì¥í•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°©ë²• 1: ì••ì¶• íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# ëª¨ë¸ í´ë” ì••ì¶•\n",
        "zip_path = 'kobert_immorality_model.zip'\n",
        "shutil.make_archive('kobert_immorality_model', 'zip', final_model_path)\n",
        "\n",
        "print(f'âœ“ ì••ì¶• íŒŒì¼ ìƒì„±: {zip_path}')\n",
        "print('ë‹¤ìš´ë¡œë“œ ì¤‘...')\n",
        "files.download(zip_path)\n",
        "\n",
        "# í‰ê°€ ê²°ê³¼ë„ ë‹¤ìš´ë¡œë“œ\n",
        "files.download(results_file)\n",
        "\n",
        "print('\\nâœ“ ëª¨ë“  íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Google Driveì— ì €ì¥í•˜ëŠ” ë°©ë²• (ì„ íƒì‚¬í•­)\n",
        "\n",
        "Google Driveì— ì €ì¥í•˜ë©´ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°©ë²• 2: Google Driveì— ì €ì¥ (ì„ íƒì‚¬í•­)\n",
        "# ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Driveì— ë³µì‚¬\n",
        "# import shutil\n",
        "# drive_model_path = '/content/drive/MyDrive/kobert_immorality_intensity_model'\n",
        "# shutil.copytree(final_model_path, drive_model_path, dirs_exist_ok=True)\n",
        "# shutil.copy(results_file, '/content/drive/MyDrive/evaluation_results.json')\n",
        "\n",
        "# print(f'âœ“ ëª¨ë¸ì´ Google Driveì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {drive_model_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## í•™ìŠµ ìš”ì•½\n",
        "\n",
        "### KoBERT Regression ëª¨ë¸ í•™ìŠµ ë¡œì§:\n",
        "\n",
        "1. **ëª¨ë¸ êµ¬ì¡°**:\n",
        "   - KoBERT Encoder (12 layers, 768 hidden size)\n",
        "   - Regression Head (Linear layer: 768 â†’ 1)\n",
        "\n",
        "2. **í•™ìŠµ ë°©ë²•**:\n",
        "   - **ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ í™œìš©**: `monologg/kobert`ëŠ” í•œêµ­ì–´ë¡œ ì‚¬ì „ í•™ìŠµëœ BERT ëª¨ë¸\n",
        "   - **Fine-tuning**: Regression íƒœìŠ¤í¬ì— ë§ê²Œ ì¶œë ¥ ë ˆì´ì–´ë§Œ ì¶”ê°€í•˜ê³  ì „ì²´ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •\n",
        "   - **í•™ìŠµë¥ **: 2e-5 (ì‘ì€ ê°’ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ì„œì„œíˆ ì¡°ì •)\n",
        "   - **Loss**: MSE (Mean Squared Error)\n",
        "\n",
        "3. **ë°ì´í„° íë¦„**:\n",
        "   - ì…ë ¥: ë°œí™” í…ìŠ¤íŠ¸ â†’ KoBERT í† í¬ë‚˜ì´ì € â†’ í† í° IDs\n",
        "   - KoBERT ì¸ì½”ë”©: í† í° IDs â†’ ë²¡í„° í‘œí˜„ (768ì°¨ì›)\n",
        "   - Regression: ë²¡í„° í‘œí˜„ â†’ Linear Layer â†’ intensity ê°’ (ì‹¤ìˆ˜)\n",
        "   - Loss: ì˜ˆì¸¡ intensity vs ì‹¤ì œ intensityì˜ MSE\n",
        "\n",
        "4. **ìµœì í™”**:\n",
        "   - AdamW Optimizer (BERT ëª¨ë¸ì˜ í‘œì¤€ ì˜µí‹°ë§ˆì´ì €)\n",
        "   - Learning Rate Warmup (ì´ˆê¸° í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€)\n",
        "   - Early Stopping (ê²€ì¦ ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ)\n",
        "\n",
        "5. **í‰ê°€ ì§€í‘œ**:\n",
        "   - MSE: í‰ê·  ì œê³± ì˜¤ì°¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
        "   - RMSE: í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (ì‹¤ì œ intensity ë‹¨ìœ„)\n",
        "   - MAE: í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (ì‹¤ì œ intensity ë‹¨ìœ„)\n",
        "   - RÂ²: ê²°ì •ê³„ìˆ˜ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
