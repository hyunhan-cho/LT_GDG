# logical_analysis/api.py

from ninja import Router, Schema
from django.shortcuts import get_object_or_404
from django.db import transaction
from datetime import datetime
from django.db.models import Count
from .schemas import AnalysisSessionOut, ClassificationResultOut
from .models import AnalysisSession, ClassificationResult
from .inference import run_pipeline  # ğŸ‘ˆ ìˆ˜ì •ëœ í•¨ìˆ˜ import

router = Router()

# 1. ìš”ì²­ ìŠ¤í‚¤ë§ˆ ë³€ê²½ (ë¦¬ìŠ¤íŠ¸ -> í†µ ë¬¸ìì—´)
class AnalyzeRequest(Schema):
    session_id: str
    text: str 

@router.post("/run-inference")
def run_inference_and_save(request, payload: AnalyzeRequest):
    """
    MainPipelineì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ DBì— ì €ì¥
    """
    # 1. MainPipeline ì‹¤í–‰
    pipeline_result = run_pipeline(payload.text, payload.session_id)
    
    # 2. DB ì €ì¥ (dataclass -> ORM ë³€í™˜)
    saved_count = 0
    with transaction.atomic():
        session, _ = AnalysisSession.objects.get_or_create(
            session_id=payload.session_id
        )
        
        # MainPipelineì˜ ê²°ê³¼(pipeline_result.results)ë¥¼ ë°˜ë³µ
        results_to_create = []
        for res in pipeline_result.results:
            results_to_create.append(ClassificationResult(
                session=session,
                text=res.text,
                label=res.label,
                label_type=res.label_type,
                confidence=res.confidence,
                probabilities=res.probabilities or {},
                timestamp=res.timestamp or datetime.now(),
                action='MONITOR',       
                alert_level='LOW',
            ))
        
        ClassificationResult.objects.bulk_create(results_to_create)
        saved_count = len(results_to_create)

    return {
        "status": "success",
        "processed_text_length": len(payload.text),
        "saved_sentences": saved_count
    }

@router.get("/{session_id}", response=AnalysisSessionOut)
def get_analysis_result(request, session_id: str):
    """
    Session IDë¡œ ë¶„ì„ ê²°ê³¼ ë° ìš”ì•½ í†µê³„ ì¡°íšŒ
    """
    session = get_object_or_404(AnalysisSession, session_id=session_id)
    results = session.results.all().order_by('created_at')

    # --- ìš”ì•½ í†µê³„ ê³„ì‚° ë¡œì§ ---
    total_count = results.count()
    
    # 1. ìœ„í—˜ë„ ê³„ì‚° (HIGH, CRITICAL ê°œìˆ˜)
    risk_count = results.filter(alert_level__in=['HIGH', 'CRITICAL']).count()
    
    # 2. ìµœê³  ìœ„í—˜ ë ˆë²¨ ì°¾ê¸°
    levels = [r.alert_level for r in results]
    if 'CRITICAL' in levels:
        highest = 'CRITICAL'
    elif 'HIGH' in levels:
        highest = 'HIGH'
    elif 'MEDIUM' in levels:
        highest = 'MEDIUM'
    else:
        highest = 'LOW'

    # 3. ê°€ì¥ ë§ì´ ë“±ì¥í•œ ë¼ë²¨(ì£¼ëœ ì˜ë„) ì°¾ê¸°
    most_common_label = "None"
    if total_count > 0:
        top_label = results.values('label').annotate(count=Count('label')).order_by('-count').first()
        if top_label:
            most_common_label = top_label['label']

    # ìš”ì•½ ê°ì²´ ìƒì„±
    summary_data = {
        "total_sentences": total_count,
        "risk_score": risk_count,
        "highest_alert": highest,
        "primary_intent": most_common_label
    }

    return {
        "session_id": session.session_id,
        "created_at": session.created_at,
        "summary": summary_data,
        "results": list(results)
    }