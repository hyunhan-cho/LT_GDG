"""
Korcen ê¸°ë°˜ ìš•ì„¤ í•„í„° (ê²½ëŸ‰í™” ë²„ì „)

ì „í™” ìƒë‹´ ë§¥ë½ì— ìµœì í™”ëœ Korcen í•„í„° êµ¬í˜„
- ë ˆë²¨-ì¹´í…Œê³ ë¦¬ ë§¤í•‘
- Baseline ê·œì¹™ê³¼ í†µí•© (ìœ„í˜‘ í‘œí˜„ ê°ì§€)
"""

import re
from typing import Tuple, Optional, Dict, List
from .baseline_rules import ProfanityBaselineRules

# ============================================================================
# í…ìŠ¤íŠ¸ ì •ê·œí™” ë§µ (í•µì‹¬ë§Œ ì¶”ì¶œ)
# ============================================================================

SINGLE_CHAR_NORMALIZATION_MAP = {
    # s ë³€í˜•
    'ð—Œ': 's', 'ð˜´': 's', 'ð™¨': 's', 'ðšœ': 's', 'ð¬': 's', 'ð‘ ': 's', 'ð’”': 's', 'ð“ˆ': 's', 
    'ð“¼': 's', 'ð”°': 's', 'ð–˜': 's', 'ð•¤': 's', 'ï½“': 's', 'ÅŸ': 's', '$': 's',
    # e ë³€í˜•
    'ð–¾': 'e', 'ð˜¦': 'e', 'ð™š': 'e', 'ðšŽ': 'e', 'ðž': 'e', 'ð‘’': 'e', 'ð’†': 'e', 'â„¯': 'e',
    'ï½…': 'e', '3': 'e', 'â‚¬': 'e',
    # x ë³€í˜•
    'ð—‘': 'x', 'ð˜¹': 'x', 'ð™­': 'x', 'ðš¡': 'x', 'ð±': 'x', 'ð‘¥': 'x', 'ð’™': 'x', 'ð“': 'x',
    'ï½˜': 'x', '*': 'x', 'âœ•': 'x', 'âœ–': 'x', 'âŒ': 'x',
    # í•œê¸€ ìžëª¨ ë³€í˜•
    'ã…—': 'ã…—', 'â”»': 'ã…—', 'â”´': 'ã…—', 'âŠ¥': 'ã…—', 'â€ ': 'ã…—',
    '^': 'ã……', 'äºº': 'ã……', 'âˆ§': 'ã……', 'Î›': 'ã……',
    'ç”˜': 'ã…‚', 'å»¿': 'ã…‚', 'ç”°': 'ã…‚', 'å£': 'ã…‚', 'æ—¥': 'ã…‚', 'ç›®': 'ã…‚',
    'å·±': 'ã„¹', 'ä¹™': 'ã„¹', 'å·²': 'ã„¹', 'å·³': 'ã„¹',
    'åœ': 'ã…', 'r': 'ã…', 'F': 'ã…', '|': 'ã…', '/': 'ã…',
    'l': 'ã…£', '1': 'ã…£', 'I': 'ã…£', '!': 'ã…£',
    'H': 'ã…', 'ã…–': 'ã…', 'ã…’': 'ã…',
    '0': 'ã…‡', 'O': 'ã…‡', 'o': 'ã…‡', 'â—¯': 'ã…‡', 'â­•': 'ã…‡', 'â—‹': 'ã…‡',
    # ì´ëª¨ì§€ ë³€í˜•
    'ðŸ¦': 'ìƒˆ', 'ðŸ”': 'ìƒˆ', 'ðŸ¦…': 'ìƒˆ',
    'ðŸ•': 'ê°œ', 'ðŸ¶': 'ê°œ', 'ðŸº': 'ê°œ',
}

MULTI_CHAR_REPLACEMENTS = {
    '_ã…£_': 'ã…—', '_/_': 'ã…—', '_|\_': 'ã…—',
    'ï¼ï¼¼': 'ã……', '/ï¼¼': 'ã……',
    '77': 'ã„²',
    'ã…‡l=ìŠ¤': 'ì„¹ìŠ¤',
    'ã…‡ã…£-ã…£': 'ì• ',
    'lã…£': 'ë‹ˆ',
    'ã…ã…£': 'ë¯¸',
}

NORMALIZATION_TABLE = str.maketrans(SINGLE_CHAR_NORMALIZATION_MAP)
URL_REGEX = re.compile(r'https?:\/\/\S+|www\.\S+')
MULTI_CHAR_REPLACEMENT_REGEX = re.compile(
    '|'.join(map(re.escape, sorted(MULTI_CHAR_REPLACEMENTS.keys(), key=len, reverse=True)))
)

# ============================================================================
# False Positive íŒ¨í„´ (ì „í™” ìƒë‹´ ë§¥ë½ì— ë§žê²Œ ì¶•ì†Œ)
# ============================================================================

FALSE_POSITIVE_PATTERNS_GENERAL = [
    'ã…—ë¨¹ì–´', 'ì˜¤ã…—', 'í•´ã…—', 'í˜¸ã…—', 'ë¡œã…—', 'ì˜¹ã…—', 'ë¡¤ã…—', 'ìš”ã…—', 'ìš°ã…—', 'í•˜ã…—',
    '8ë¶„', '8ì‹œ', '8ì‹œë°œ',
    'ë°œë‹¦', 'ë‹¤ì‹œë°©', 'ì‹œë°œìŒ', 'ì‹œë°œíƒì‹œ', 'ì‹œë°œìžë™ì°¨', 'ì •ì¹˜ë°œ', 'ì‹œë°œì ', 'ì‹œë°œìœ ',
    'ì‹œë°œì—­', 'ì•„ì €ì”¨ë°”', 'ì•„ì €ì”¨ë°œ', 'ì˜¤ë¦¬ë°œ', 'ë°œë', 'ë‹¤ì‹œë°”', 'ë‹¤ì‹œíŒ”',
    'ë°œì‚¬', 'ë¬´ì‹œë°œì–¸', 'ì¼ì‹œë¶ˆ', 'ìš°ë¦¬', 'í˜¹ì‹œ', 'ì•„ì €ì”¨', 'ë°”ë¡œ', 'ì €ê±°ì‹œ',
    'í”¼ì‹œë°©', 'í”¼ì”¨ë°©', 'ë°©ìž¥', 'ì— ì”¨ë°©', 'ë¹¨ë¦¬', 'ë²Œê¸ˆ', 'ì‹œë°©í–¥', 'ë¶ˆë²•', 'ë°œí‘œ', 'ë°©ì†¡', 'ì—­ì‹œ',
    'ìžˆì§€', 'ì—†ì§€', 'í•˜ì§€', 'ì•Œì•˜ì§€', 'ëª°ëžì§€', 'ê·¼ë°',
    'ìƒˆë¡œ', 'ì„¸ë¼ë¨¹', 'ê³ ì–‘ì´ìƒˆë¼', 'í˜¸ëž‘ì´ìƒˆë¼', 'í‚¤ë³´ë“œ', 'ìƒˆë¼ì†',
    '0ê°œ', '1ê°œ', '2ê°œ', '3ê°œ', '4ê°œ', '5ê°œ', '6ê°œ', '7ê°œ', '8ê°œ', '9ê°œ',
    '1ë…„', '2ë…„', '3ë…„', '4ë…„', '5ë…„', '6ë…„', '7ë…„', '8ë…„', '9ë…„',
    'ìž¬ë°Œê²Œë†ˆ', 'ë…„ìƒ', 'ë¬´ì§€ê°œìƒ‰', 'ë– ëŒì´ê°œ', 'ì—ê²Œ', 'ë„˜ëŠ”', 'ì†Œê°œ', 'ìƒê¸´ê²Œ', 'ë‚ ê°œê°™ë‹¤',
]

FALSE_POSITIVE_PATTERNS_MINOR = [
    'ê±°ë¯¸', 'ì¹œêµ¬', 'ê°œë¯¸', 'ì´ë¯¸ì¹œ', 'ë¯¸ì¹œì¦', 'ë™ê·¸ë¼ë¯¸',
    'ë’¤ì ¸ë´ì•¼', 'ë’¤ì§ˆë»”', 'ë’¤ì ¸ë³´ë‹¤', 'ë’¤ì ¸ë³´ëŠ”', 'ë’¤ì ¸ë³´ê³ ', 'ë’¤ì ¸ê°„ë‹¤', 'ë’¤ì ¸ì„œ',
]

FALSE_POSITIVE_PATTERNS_SEXUAL = [
    'ë³´ì§€ë„ëª»', 'ë³´ì§€ë„ì•Š', 'ì¸ê°€ë³´ì§€', 'ë©´ì ‘ë³´ì§€', 'ì˜í™”ë³´ì§€', 'ì• ë‹ˆë³´ì§€', 'ë§Œí™”ë³´ì§€', 'ì‚¬ì§„ë³´ì§€',
    'ë³´ì§€ë§ˆ', 'ë³´ì§€ë§', 'ì•ˆë³´ì§€ë§Œ', 'ì •ë³´', 'ì§€íŒ¡ì´', 'í–‰ë³´', 'ë°”ë³´ì§€', 'ë¬¼ì–´ë³´ì§€',
    'ì–¸ì œìžì§€', 'ìž ìžì§€', 'ìžì§€ë§ìžê³ ', 'ì§€ê¸‰', 'ë‚¨ìžì§€', 'ì—¬ìžì§€', 'ê°ìžì§€',
    'ê°œë°œìž', 'ê´€ë¦¬ìž', 'ì•½íƒˆìž', 'í˜¼ìž', 'ìžì§€ì›', 'ì‚¬ìš©ìž', 'ê²½ë ¥ìž', 'ì§€ì‹', 'ìžì§€ë§ˆ',
    'ì•¼ìŠ¤ì˜¤', 'í¬ì‹œì•¼', 'ì¹´êµ¬ì•¼', 'ìŠ¤íŒŒì´', 'ë§ì´ì•¼', 'ìŠ¤í‹°ë¸Œ', 'ìŠ¤ì¿¼ë“œ',
]

FALSE_POSITIVE_PATTERNS_BELITTLE = [
    'ë ¤ìš´ì§€', 'ë¬´ì„œìš´ì§€', 'ë¼ìš´ì§€', 'ìš´ì§€ë²•', 'ì‹¸ìš´ì§€', 'ìš´ì§€ë²„ì„¯', 'ìš´ì§€ë¦°ë‹¤', 'ê¹”ë³´ë‹¤',
    '1ë…„', '2ë…„', '3ë…„', '4ë…„', '5ë…„', '6ë…„', '7ë…„', '8ë…„', '9ë…„', '0ë…„',
]

FALSE_POSITIVE_PATTERNS_RACE = ['í‘í˜•ë‹˜']
FALSE_POSITIVE_PATTERNS_PARENT = ['ã„´ã„´', 'ë¯¸êµ­', 'ì—„ì°½ëª»']
FALSE_POSITIVE_PATTERNS_POLITICS = [
    'ì¹´ì¹´ì˜¤í†¡', 'ì¹´í†¡', 'ì¹´íŽ˜', 'í•˜ë‹¤ê°€', 'ë¨¹ë‹¤ê°€', 'ì¹´ì™€ì´', 'ì¹´ì¸ ', 'ì¹´ë ˆ',
    'ë‹ˆê°€', 'ë‚´ê°€', 'ë„ˆê°€', 'ìš°ë¦¬ê°€', 'ë„ˆí¬ê°€', 'ì¹´ì¹´ì˜¤', 'ì¹´ë“œ',
]

# False Positive ì •ê·œì‹ ì»´íŒŒì¼
FP_REGEX_GENERAL = re.compile('|'.join(map(re.escape, FALSE_POSITIVE_PATTERNS_GENERAL)))
FP_REGEX_MINOR = re.compile('|'.join(map(re.escape, FALSE_POSITIVE_PATTERNS_MINOR)))
FP_REGEX_SEXUAL = re.compile('|'.join(map(re.escape, FALSE_POSITIVE_PATTERNS_SEXUAL)))
FP_REGEX_BELITTLE = re.compile('|'.join(map(re.escape, FALSE_POSITIVE_PATTERNS_BELITTLE)))
FP_REGEX_RACE = re.compile('|'.join(map(re.escape, FALSE_POSITIVE_PATTERNS_RACE)))
FP_REGEX_PARENT = re.compile('|'.join(map(re.escape, FALSE_POSITIVE_PATTERNS_PARENT)))
FP_REGEX_POLITICS = re.compile('|'.join(map(re.escape, FALSE_POSITIVE_PATTERNS_POLITICS)))

# ============================================================================
# ìš•ì„¤ íŒ¨í„´ (í•µì‹¬ë§Œ ì¶”ì¶œ)
# ============================================================================

GENERAL_PROFANITY_PATTERNS = [
    'ã…—', 'ì”¨8', '18ì•„', '18ë†ˆ', 'tã…‚', 'të°œ', 'ã…†ã…', 'sibal', 'sival', 'sibar', 'sibak', 'sipal',
    'tlbal', 'tlval', 'tlbar', 'tlbak', 'tlpal', 'tlqk', 'ì‹œë°œ', 'ì‹œval', 'ì‹œbar',
    'ì‹œbak', 'ì‹œpal', 'ì‹œqk', 'sië°”', 'sië°œ', 'sië¶ˆ', 'sië¹¨', 'siíŒ”', 'tlë°”', 'tlë°œ', 'tlë¶ˆ', 'tlë¹¨', 'tlíŒ”',
    'siba', 'tlba', 'siva', 'tlva', 'tlqkf', '10ë°œë†ˆ', '10ë°œë…„', 'tlqkd', 'si8', '10rë†ˆ', 'ì‹œ8', 'ì‹­8',
    's1bal', 'sibì•Œ', 'ì”¨x', 'siã…‚', 'ä¸¨ë°œ', 'ä¸¨ë²Œ', 'ä¸¨ë°”', 'ã……1', 'ì‹œã…£', 'ì”¨ã…£', '8ì‹œë°œ',
    'ã…†ë°œ', 'ã……ë°œ', 'ã……ã…‚', 'ã…†ã…‚', 'ã…†ë°”', 'ã……ë°”', 'ì‹œã…‚ã…', 'ã……ã…‚ã…', 'ì‹œã…ã„¹', 'ì”¨ã…ã„¹',
    'ã……ë¶ˆ', 'ã…†ë¶ˆ', 'ã……ì ', 'ã…†ë¿”', 'ã…†ã…£ë°œ', 'ã……ã…Ÿë°œ', 'ã……ã…£ã…‚ã…', 'ã…£ë°”ì•Œ', 'ã……ë²Œ',
    'ã…†ì‚ë¼', 'ì”¨ã…ƒ', '^^/ë°œ', 'ì‹œë´˜', 'ì”¨ë´˜', 'ì”¨ë°”', 'ì‹œë°”', 'ìƒ¤ë°œ', 'ì”Œë°œ', 'ì”¹ë°œ', 'ì‹œë²Œ',
    'ì‹œíŒ”', 'ì‹¯íŒ”', 'ì”¨ë¹¨', 'ì”¨ëž¼', 'ì”¨íŒŒ', 'ë ë°œ', 'ë¡ë°œ', 'ë¸ë°œ', 'ì‹¸ë°œ', 'ì‹­ë°œ', 'ìŠˆë°œ',
    'ì•¼ë°œ', 'ì”¨ë¶ˆ', 'ì”¨ëž„', 'ì‰¬ë°œ', 'ì“°ë°œ', 'ì“”ë°œ', 'ìŒ°ë°œ', 'ì’¸ë°œ', 'ì”¨íŒ”',
    'wlfkf', 'gëž„', 'gëŸ´', 'gë¡¤', 'gë¢€', 'giral', 'ziëž„', 'jiëž„', 'ã…ˆã„¹', 'ì§€ã„¹', 'ã…ˆëž„', 'ã…ˆë¼',
    'ì§€ëž„', 'ì°Œëž„', 'ì§€ëŸ´', 'ì§€ë¡¤', 'ëž„ì§€', 'ì¥ëž„', 'ì®œëž„', 'ì§€ë¢€', 'ë„ëž„',
    'ã…„', 'ã…‚ã……', 'ë³‘ã……', 'ã…‚ì‹ ', 'ã…•ã…‡ì‹ ', 'ã…‚ã…‡ì‹ ', 'ë·°ì‹ ', 'ë³‘ì‹ ', 'ë³‘ë”±', 'ë²¼ì‹ ', 'ë¶±ì‹ ',
    'ë¼ì‹ ', 'ë¿½ì‹ ', 'ì‚¥ì‹ ', 'ë³‘ì‹œë‹ˆ', 'ë³‘í˜•ì‹ ', 'ëµ¹ì‹ ', 'ë³‘ê¸´', 'ë¹„ì‘ì‹ ',
    'ì—¼ë³‘', 'ì— ë³‘', 'ì˜˜ë³‘', 'ì–¨ë³‘', 'ì˜˜ë¼',
    'êº¼ì ¸',
    'ì—¿ê°™', 'ì—¿ê°€íŠ¼', 'ì—¿ë¨¹ì–´', 'ë­£ê°™ì€',
    'rotorl', 'rotprl', 'sibìƒˆ', 'ahë¼', 'sã…ë¼', 'xë¼',
    'ã……ã„²', 'ã……ë¼', 'ã…†ë¼', 'ìƒ‰ã„²ã…£', 'ã…†ã…ã„²ã…‘', 'ã…†ã…ã„²ã…£', 'ìƒˆë¼', 'ì‰ë¦¬', 'ìŒ”ë¼', 'ìŒë¼',
    'ìŽ¼ë¼', 'ìŒ¬ë¼', 'ìƒ ë¼', 'ì„¸ë¼', 'ìƒŠ', 'ìŒ–', 'ì„º', 'ìŽ†', 'ì‹­ìƒˆ', 'ìƒˆí‚¤', 'ì”¹ìƒ‰', 'ìƒˆê¹Œ',
    'ìƒˆêº„', 'ìƒ›ë¼', 'ìƒˆë€Œ', 'ìƒˆë ', 'ìƒˆìº¬', 'ìƒ‰êº„', 'ìƒ‰ë¼', 'ì„¹ížˆ', 'ì…ê¸°', 'ì…ë¼', 'ì…ê¸°',
    'ì…°ë¼', 'ì…°ë¦¬', 'ì‰êº„', 'ì‹­ìƒ‰êº„', 'ì‹­ë–¼ë¼', 'ì‹­ë°êº„', 'ì‹­ë•Œë¼', 'ì‹­ìƒˆêº„', 'ì‹­ìƒˆìº¬', 'ì‰‘ížˆ',
    'ì”¹ìƒˆê¸°', 'ê³ ì•„ìƒˆê¸°', 'ìƒ ê¸°', 'ì• ìƒˆê¸°', 'ì´ìƒˆê¸°', 'ëŠê·¸ìƒˆê¸°', 'ìž¥ì• ìƒˆê¸°',
    'wê°™ì€', 'ã…ˆê°™', 'ã…ˆë§', 'ã…ˆê¹Œ', 'ã…ˆê²½', 'ã…ˆê°€íŠ¼', 'ì¢†', 'ì´Ÿ', 'ì¡°ê¹Œ', 'ì¢ˆ', 'ì«’', 'ì¡·',
    'ì¢ƒ', 'ì¤®', 'ì¢‹ê°™', 'ì¢ƒê°™', 'ì¢ƒë¬¼', 'ì¢ƒë°¥', 'ì¤«', 'ì¢‹ë°¥', 'ì¢‹ë¬¼', 'ì¢‡',
    'ì…', 'ì”¨ì•™', 'ì”¨ì–‘', 'ìƒ¤ì•™', 'ìŒ°ì•™',
    'ë»‘ìœ ', 'ë»í‚¹', 'ë»í', 'ë¹¡í', 'ë¿©í', 'ë»‘í', 'ë¹¡ìœ ', 'ë»’í',
    'ë‹¥ì³', 'ë‹­ì³', 'ë‹¥ì¹˜ë¼', 'ì•„ê°€ë¦¬í•´',
    'dogìƒˆ', 'ê°œã…ìƒ‰',
    'ê°œê°™', 'ê°œê°€íŠ¼', 'ê°œì‰‘', 'ê°œìŠ¤í‚¤', 'ê°œì„¸ë¼', 'ê°œìƒ‰ížˆ', 'ê°œê°€ë‡¬', 'ê°œìƒˆê¸°', 'ê°œìŒ”ê¸°', 'ê°œìŒ”ë¼',
    'ê°œì†Œë¦¬', 'ê°œë…„', 'ê°œë“œë¦½', 'ê°œë¼ì§€', 'ê°œì”¹ì°½', 'ê°œê°„ë‚˜', 'ê°œìŠ¤ë¼', 'ê°œì„¹ê¸°',
    'ê°œìžì‹', 'ê°œë•Œêº„', 'ê°œë•Œë¼', 'ê°œë°œë‚¨ì•„', 'ê°œìƒ›ë¼', 'ê°œê°€ë“ ', 'ê°œê°€ëœ¬', 'ê°œê°€í„´', 'ê°œê°€íˆ°',
    'ê°œê°‡ì€', 'ê°œê°ˆë³´', 'ê°œê±¸ë ˆ', 'ê°œë„ˆë§ˆ', 'ê°œë„ˆë¯€', 'ê°œë„Œ', 'ê°œë„˜', 'ê°œë…€ë‚˜',
    'ê°œë…¸ë§ˆ', 'ê°œë…¸ë¬´ìƒˆë¼', 'ê°œë…¼', 'ê°œë†ˆ', 'ê°œë‡¨ë‚˜', 'ê°œë‡¬', 'ê°œë‡¸', 'ê°œë‡½', 'ê°œëˆ”', 'ê°œëŠë§ˆ',
    'ê°œëŠ ', 'ê°œëž™ê¸°', 'ê°œë ¨', 'ê°œë°œë‚¨ì•„', 'ê°œë°œë‡¬', 'ê°œìƒ‰', 'ê°œìƒ‰ê¸°',
    'ê°œìƒ‰ë¼', 'ê°œìƒ›í‚¤', 'ê°œìƒ›í‚¹', 'ê°œìƒ›ížˆ', 'ê°œìƒœë¼', 'ê°œìƒí‚¤', 'ê°œìƒ ', 'ê°œìƒ¤ë¼', 'ê°œìƒ¤í‚¥',
    'ê°œì§€ëž„', 'ê°œì§€ëŸ´', 'ê°œì°½ë…„', 'ê°œí—ˆëŸ¬', 'ê°œí—ˆë²Œë…„', 'ê°œí˜¸ëŸ¬', 'ê°œí˜¸ë¡œ', 'ê°œí›„ëž„', 'ê°œí›„ë ˆ',
    'ê°œí›„ë¡œ', 'ê°œí›„ìž¥', 'ê²Œê°€íŠ¼', 'ê²Œê°™ì€', 'ê²Œë…„', 'ê²Œë†ˆ', 'ê²Œìƒˆë¼', 'ê²Œìƒ‰', 'ê²Œìƒ‰ê¸°', 'ê²Œìƒ‰ë¼',
]

MINOR_PROFANITY_PATTERNS = [
    'ã…ã…Š', 'ã…ì¹œ', 'ã…ì³¤', 'aã…£ì¹œ', 'meì¹œ', 'ë¯¸ã…Š', 'diì¹œ',
    'ë¯¸ì¹œë†ˆ', 'ë¯¸ì¹œìƒˆë¼',
    'ê¼½ëƒ', 'ê¼½ë‹ˆ', 'ê¼½ë‚˜',
    'ë’¤ì ¸', 'ë’ˆì ¸', 'ë’ˆì§„', 'ë’ˆì§ˆ', 'ë””ì ¸ë¼', 'ë””ì§„ë‹¤', 'ë””ì§ˆëž˜', 'ë’¤ì§ˆ',
]

SEXUAL_PROFANITY_PATTERNS = [
    'â“‘â“žâ“©â“˜', 'bozi', 'ë³´ã…ˆã…£', 'ë³´ì§€', 'ë²„ì§€ë¬¼', 'ë²„ì§“ë¬¼', 'ë³´ì§“', 'ê°œë³´ì¦¤', 'ê°œë³´ì§€',
    'jaì§€', 'ã…ˆã…ˆë¹¨', 'ìžã…ˆ', 'ã…ˆì§€ë¹¨', 'ìžì§€', 'ìžì§“', 'ìž¦ì´', 'ìŸˆì§€',
    'sex', 'sìŠ¤', 'xìŠ¤', 'seìŠ¤', 'ã……ã…”ã……ã„±', 'ì´=ìŠ¤', 'ì„¹ã……', 'ì„¸ã„±ã……', 'ì„¹ìŠ¤', 'ì„»', 'ì‰‘ìŠ¤', 'ì„¿ìŠ¤',
    'ê¼¬3', 'ê¼¬íˆ­íŠ€', 'ê¼¬í†¡íŠ€', 'ë¶ˆì•Œ', 'ë¶€ëž„', 'ë½•ì•Œ', 'ë¿…ì•Œ', 'ë¿Œëž„', 'ë¿”ì•Œ', 'ê°œë¶€ë‹¬', 'ê°œë¶€ëž„',
    'ì˜¤ë‚˜í™', 'ì˜¤ë‚˜í™€', 'ã…‡ã„´í™€', 'í…ê°€', 'ë°”ì´ë¸Œë ˆì´í„°', 'ì”¹í•˜ë‹¤', 'ë§¤ì¶˜ë¶€', 'ì„±ë…¸ì˜ˆ',
    'ë”¸ë”¸ì´', 'ì§ˆì‹¸', 'ìžìœ„ë‚¨', 'ìžìœ„ë…€', 'í°ì„¹', 'í¬ë¥´ë…¸', 'í°ì„¸ì—‘', 'í°ì‰‘', 'í°ìŽ…',
    'gìŠ¤íŒŸ', 'ì§€ìŠ¤íŒŸ', 'í¬ë¦¬í† ë¦¬ìŠ¤', 'í´ë¦¬í† ë¦¬ìŠ¤', 'íŽ˜ë‹ˆìŠ¤', 'ì• ë„', 'ì –ê¹Œ', 'ì –ê°€íŠ¼',
    'jaìœ„', 'ìžìœ„', 'ê³ ìžìƒˆë¼', 'ê³ ì¸„', 'êº¼ì¶”', 'ê¼¬ì¶”',
]

BELITTLE_PROFANITY_PATTERNS = [
    '10ë ¨', 'ë”°ê¹Œë¦¬', 'ìž¥ì• ë…„', 'ì°ë”°ë…„', 'ì‹¸ê°€ì§€', 'ì°½ë…„', 'ì…ë…„', 'ë²„ëŸ¬ì§€', 'ê³ ì•„ë…„', 'ê°œê°„ë…„',
    'ì°½ë…€', 'ë¨¸ì €ë¦¬', 'ì”¹ì“°ëž˜ê¸°', 'ì”¹ì“°ë ˆê¸°', 'ì”¹ìž¥ìƒ', 'ì”¹ìžì‹', 'ìš´ì§€', 'ê¸‰ì‹ì¶©', 'í‹€ë”±ì¶©',
    'í•œë‚¨ì¶©', 'ì •ì‹ ë³‘ìž', 'ì¤‘ìƒì•„', 'ëŒíŒ”ì´', 'ê¹€ì¹˜ë…€', 'í°íŒ”ì´', 'í‹€ë”±ë…„', 'ê°™ì€ë…„', 'ê°œë¼ì¤‘',
    'ë¹¡ëŒ€ê°€ë¦¬', 'ë”ëŸ¬ìš´ë…„', 'ëŒì•„ì´', 'ë˜ë¼ì´', 'ìž¥ì• ë ¤', 'ìƒ¹ë†ˆ', 'ê¹€ì¹˜ë‚¨', 'ê¹€ì¹˜ë…€',
]

RACE_PROFANITY_PATTERNS = [
    'ê¹œë‘¥ì´', 'í‘í˜•', 'ì¡°ì„¼ì§„', 'ì§±ê°œ', 'ì§±ê¹¨', 'ì§±ê»˜', 'ì§±ê²Œ', 'ìª½ë°”ë¦¬', 'ìª½íŒŒë¦¬', 'ë¹¨ê°±ì´',
    'ë‹ˆê·¸ë¡œ', 'ì½”ìŸì´', 'ì¹­ì´', 'ì¹­ì±™ì´', 'ì„¬ìˆ­ì´', 'ì™œë†ˆ', 'ì§±ê¼´ë¼', 'ì„¬ì§±ê¹¨',
]

PARENT_PROFANITY_PATTERNS = [
    'ã„´1ã„±', 'ã„´1ã…', 'ëŠê¸ˆã…', 'ã„´ã„±ë§ˆ', 'ã„´ã„±ë¹ ', 'ã„´ê¸ˆë¹ ', 'ã…‡Hë¯¸', 'ã„´1ì—ë¯¸', 'ëŠ¬ì• ë¯¸',
    'ã„´ã„±ã…', 'ã„´ê¸ˆë§ˆ', 'ëŠ¬ê¸ˆë§ˆ',
    'ëŠê¸ˆë§ˆ', 'ëŠê·¸ì—„ë§ˆ', 'ëŠ‘ì—„ë§ˆ', 'ëŠ‘ê¸ˆë§ˆ', 'ëŠê·¸ì• ë¯¸', 'ë„‰ì—„ë§ˆ', 'ëŠê·¸ë¶€ëª¨', 'ëŠê·¸ì• ë¹„',
    'ëŠê¸ˆë¹ ', 'ëŠê·¸ë©”', 'ëŠê·¸ë¹ ', 'ë‹ˆë¯¸ì”¨', 'ë‹ˆë¯¸ì”¹',
    'ëŠê·¸ë§ˆ', 'ë‹ˆì—„ë§ˆ', 'ì—„ì°½', 'ì— ì°½', 'ë‹ˆë¯¸ëŸ´', 'ëˆ„êµ¼ë§ˆ', 'ëŠê¸ˆ',
]

POLITICS_PROFANITY_PATTERNS = [
    "ë…¸ì‹œê°œ", "ë…¸ì•Œë¼", "ë‡Œì‚¬ëª¨", "ë‡Œë¬¼í˜„", "ì‘ë””ì‹œí‹°",
    "ê·€ê±¸ì´ì•„ë¹ ", "ë‹¬ì°½", "ëŒ€ê¹¨ë¬¸", "ë¬¸ìž¬ì•™", "ë¬¸ì£„ì•™", "ë¬¸ì£„ì¸", "ë¬¸í¬ì˜ˆê±°", "í› í› í› ", "ë¬¸ë¹ ",
    "ê·¼í˜œì–´", "ê¸¸ë¼ìž„", "ë‚˜ëŒ€ë¸”ì¸ ", "ë‹­ê·¼í˜œ", "ëŒ“í†µë ¹", "ë ˆì´ë””ê°€ì¹´", "ë°”ìœë²Œê¿€",
    "ê°€ì¹´", "ì´ëª…ë°•ê·¼í˜œ",
]

SPECIAL_PROFANITY_PATTERNS = ["ðŸ–•ðŸ»", "ðŸ‘ŒðŸ»ðŸ‘ˆðŸ»", "ðŸ‘‰ðŸ»ðŸ‘ŒðŸ»", "ðŸ¤ðŸ»", "ðŸ–•", "ðŸ–•ðŸ¼", "ðŸ–•ðŸ½", "ðŸ–•ðŸ¾", "ðŸ–•ðŸ¿"]

# ì •ê·œì‹ ì»´íŒŒì¼
P_REGEX_GENERAL = re.compile('|'.join(map(re.escape, GENERAL_PROFANITY_PATTERNS)))
P_REGEX_MINOR = re.compile('|'.join(map(re.escape, MINOR_PROFANITY_PATTERNS)))
P_REGEX_SEXUAL = re.compile('|'.join(map(re.escape, SEXUAL_PROFANITY_PATTERNS)))
P_REGEX_BELITTLE = re.compile('|'.join(map(re.escape, BELITTLE_PROFANITY_PATTERNS)))
P_REGEX_RACE = re.compile('|'.join(map(re.escape, RACE_PROFANITY_PATTERNS)))
P_REGEX_PARENT = re.compile('|'.join(map(re.escape, PARENT_PROFANITY_PATTERNS)))
P_REGEX_POLITICS = re.compile('|'.join(map(re.escape, POLITICS_PROFANITY_PATTERNS)))
P_REGEX_SPECIAL = re.compile('|'.join(map(re.escape, SPECIAL_PROFANITY_PATTERNS)))

EXACT_MATCH_PROFANITY = {'tq', 'qt'}

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def apply_multi_char_replacements(text: str) -> str:
    """ë‹¤ì¤‘ ë¬¸ìž ì¹˜í™˜ ì ìš©"""
    def replace_match(match):
        return MULTI_CHAR_REPLACEMENTS[match.group(0)]
    return MULTI_CHAR_REPLACEMENT_REGEX.sub(replace_match, text)

def preprocess_text(text: str, level: str) -> str:
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ì •ê·œí™”)"""
    processed_text = text.lower()
    processed_text = processed_text.translate(NORMALIZATION_TABLE)
    processed_text = apply_multi_char_replacements(processed_text)
    processed_text = re.sub(r'\s+', '', processed_text)
    
    if level == 'minor':
        processed_text = re.sub('ë…„', 'ë†ˆ', processed_text)
        processed_text = re.sub('ë ¨', 'ë†ˆ', processed_text)
    elif level == 'belittle':
        processed_text = re.sub('ë‡¬', 'ë ¨', processed_text)
        processed_text = re.sub('ë†ˆ', 'ë ¨', processed_text)
        processed_text = re.sub('ë„˜', 'ë ¨', processed_text)
        processed_text = re.sub('ë ¨', 'ë…„', processed_text)
    elif level == 'sexual' and 'ë³´g' in processed_text:
        processed_text = re.sub('ë³´g', 'ë³´ì§€', processed_text)
    
    return processed_text

def get_false_positive_regex(level: str):
    """ë ˆë²¨ë³„ False Positive ì •ê·œì‹ ë°˜í™˜"""
    level_map = {
        'general': FP_REGEX_GENERAL,
        'minor': FP_REGEX_MINOR,
        'sexual': FP_REGEX_SEXUAL,
        'belittle': FP_REGEX_BELITTLE,
        'race': FP_REGEX_RACE,
        'parent': FP_REGEX_PARENT,
        'politics': FP_REGEX_POLITICS,
    }
    return level_map.get(level)

def get_profanity_regex(level: str):
    """ë ˆë²¨ë³„ ìš•ì„¤ ì •ê·œì‹ ë°˜í™˜"""
    level_map = {
        'general': P_REGEX_GENERAL,
        'minor': P_REGEX_MINOR,
        'sexual': P_REGEX_SEXUAL,
        'belittle': P_REGEX_BELITTLE,
        'race': P_REGEX_RACE,
        'parent': P_REGEX_PARENT,
        'politics': P_REGEX_POLITICS,
        'special': P_REGEX_SPECIAL,
    }
    return level_map.get(level)

def get_final_filter_regex_str(level: str) -> str:
    """ë ˆë²¨ë³„ ìµœì¢… í•„í„° ì •ê·œì‹ ë¬¸ìžì—´ ë°˜í™˜"""
    if level in ['general', 'sexual', 'parent', 'special', 'politics']:
        return r'[^a-z0-9ã„±-ã…Žã…-ã…£ê°€-íž£ã…—@=\-_]+'
    elif level in ['minor', 'belittle', 'race']:
        return r'[^ã„±-ã…Žã…-ã…£ê°€-íž£]+'
    return r'[^a-zA-Z0-9ã„±-ã…Žã…-ã…£ê°€-íž£\s]+'

def check_and_report_profanity_pattern(text: str, level: str = 'general') -> Optional[str]:
    """
    íŠ¹ì • ë ˆë²¨ì—ì„œ ìš•ì„¤ íŒ¨í„´ ê°ì§€
    
    Returns:
        ê°ì§€ëœ ìš•ì„¤ íŒ¨í„´ ë¬¸ìžì—´ ë˜ëŠ” None
    """
    text_no_urls = URL_REGEX.sub('', text)
    processed_text = preprocess_text(text_no_urls, level)
    
    # False Positive ì œê±°
    fp_regex = get_false_positive_regex(level)
    text_after_fp = fp_regex.sub('', processed_text) if fp_regex else processed_text
    
    # ìµœì¢… í•„í„° ì ìš©
    if level == 'special':
        final_processed_text = text_after_fp
    else:
        final_filter_regex_str = get_final_filter_regex_str(level)
        final_processed_text = re.sub(final_filter_regex_str, '', text_after_fp)
    
    # ìš•ì„¤ íŒ¨í„´ ë§¤ì¹­
    profanity_regex = get_profanity_regex(level)
    if profanity_regex:
        match = profanity_regex.search(final_processed_text)
        if match:
            return match.group(0)
    
    # ì •í™•í•œ ë§¤ì¹­ (general ë ˆë²¨ë§Œ)
    if processed_text in EXACT_MATCH_PROFANITY and level == 'general':
        return processed_text
    
    return None

# ============================================================================
# ë ˆë²¨-ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (ì „í™” ìƒë‹´ ë§¥ë½)
# ============================================================================

KORCEN_TO_CATEGORY_MAP: Dict[str, str] = {
    'general': 'PROFANITY',        # ì¼ë°˜ ìš•ì„¤ â†’ PROFANITY
    'minor': 'PROFANITY',          # ê²½ë¯¸í•œ ìš•ì„¤ â†’ PROFANITY
    'sexual': 'SEXUAL_HARASSMENT', # ì„±ì  ìš•ì„¤ â†’ SEXUAL_HARASSMENT
    'belittle': 'INSULT',          # ë¹„í•˜ í‘œí˜„ â†’ INSULT
    'race': 'HATE_SPEECH',         # ì¸ì¢… ì°¨ë³„ â†’ HATE_SPEECH
    'parent': 'INSULT',            # ë¶€ëª¨ ê´€ë ¨ ìš•ì„¤ â†’ INSULT
    'politics': 'HATE_SPEECH',     # ì •ì¹˜ ê´€ë ¨ â†’ HATE_SPEECH
    'special': 'PROFANITY',        # íŠ¹ìˆ˜ ë¬¸ìž â†’ PROFANITY
}

# ë ˆë²¨ë³„ ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜
LEVEL_CONFIDENCE_WEIGHTS: Dict[str, float] = {
    'general': 0.8,      # ë†’ì€ ì‹ ë¢°ë„
    'minor': 0.6,       # ì¤‘ê°„ ì‹ ë¢°ë„
    'sexual': 0.9,      # ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„ (CRITICAL)
    'belittle': 0.5,    # ì¤‘ê°„ ì‹ ë¢°ë„
    'race': 0.7,        # ë†’ì€ ì‹ ë¢°ë„
    'parent': 0.6,      # ì¤‘ê°„ ì‹ ë¢°ë„
    'politics': 0.5,    # ë‚®ì€ ì‹ ë¢°ë„ (ë§¥ë½ ì˜ì¡´ì )
    'special': 0.7,     # ë†’ì€ ì‹ ë¢°ë„
}

# ============================================================================
# KorcenFilter í´ëž˜ìŠ¤
# ============================================================================

class KorcenFilter:
    """Korcen ê¸°ë°˜ ìš•ì„¤ í•„í„° (ì „í™” ìƒë‹´ ë§¥ë½ ìµœì í™”)"""
    
    def __init__(self):
        """Korcen í•„í„° ì´ˆê¸°í™”"""
        self.baseline_rules = ProfanityBaselineRules()
    
    def check_profanity(self, text: str) -> Tuple[bool, Optional[str], float]:
        """
        ìš•ì„¤ ê°ì§€ ë° ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        
        Returns:
            (is_profanity, category, confidence)
            - is_profanity: ìš•ì„¤ ê°ì§€ ì—¬ë¶€
            - category: ê°ì§€ëœ ì¹´í…Œê³ ë¦¬ (PROFANITY, SEXUAL_HARASSMENT, HATE_SPEECH, INSULT)
            - confidence: ì‹ ë¢°ë„ (0.0-1.0)
        """
        # 1. Baseline ê·œì¹™ìœ¼ë¡œ ìœ„í˜‘ í‘œí˜„ ê°ì§€ (ìµœìš°ì„ )
        is_threat, threat_category, threat_confidence = self.baseline_rules.detect_profanity(text)
        if is_threat and threat_category == "VIOLENCE_THREAT":
            return True, threat_category, threat_confidence
        
        # 2. Korcen ë ˆë²¨ë³„ ê°ì§€
        detected_levels: List[Tuple[str, str]] = []  # (level, category)
        
        # ê°ì§€í•  ë ˆë²¨ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ)
        check_levels = ['sexual', 'general', 'race', 'belittle', 'parent', 'minor', 'politics', 'special']
        
        for level in check_levels:
            detected_pattern = check_and_report_profanity_pattern(text, level)
            if detected_pattern:
                category = KORCEN_TO_CATEGORY_MAP.get(level, 'PROFANITY')
                detected_levels.append((level, category))
        
        # 3. ê²°ê³¼ ì²˜ë¦¬
        if not detected_levels:
            return False, None, 0.0
        
        # 4. ê°€ìž¥ ë†’ì€ ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ ì„ íƒ
        # ìš°ì„ ìˆœìœ„: SEXUAL_HARASSMENT > VIOLENCE_THREAT > HATE_SPEECH > PROFANITY > INSULT
        priority_order = ['SEXUAL_HARASSMENT', 'VIOLENCE_THREAT', 'HATE_SPEECH', 'PROFANITY', 'INSULT']
        
        selected_category = None
        selected_level = None
        
        for priority_cat in priority_order:
            for level, category in detected_levels:
                if category == priority_cat:
                    selected_category = category
                    selected_level = level
                    break
            if selected_category:
                break
        
        # ê¸°ë³¸ê°’ (ì—†ìœ¼ë©´ ì²« ë²ˆì§¸)
        if not selected_category:
            selected_level, selected_category = detected_levels[0]
        
        # 5. ì‹ ë¢°ë„ ê³„ì‚°
        base_confidence = LEVEL_CONFIDENCE_WEIGHTS.get(selected_level, 0.6)
        # ì—¬ëŸ¬ ë ˆë²¨ì—ì„œ ê°ì§€ë˜ë©´ ì‹ ë¢°ë„ ì¦ê°€
        if len(detected_levels) > 1:
            base_confidence = min(base_confidence + 0.1 * (len(detected_levels) - 1), 1.0)
        
        return True, selected_category, base_confidence

